{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepSpeedMultiModalityPerceiver.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jlISx-HYFqt"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/fac2003/repro_deepspeed_multi_modality_perceiver_stage_3/blob/main/DeepSpeedMultiModalityPerceiver.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-xn6jx2BKY1",
        "outputId": "b0229888-d08c-4770-a1dc-8af5b1055a6c"
      },
      "source": [
        "! pip install perceiver-multi-modality-pytorch==1.1.0 \n",
        "# !  pip install deepspeed==0.3.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting perceiver-multi-modality-pytorch==1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/a5/ba023466014dfa90c10bcd68ac546376a41c27476823c01da0a6d628590a/perceiver_multi_modality_pytorch-1.1.0-py3-none-any.whl\n",
            "Collecting einops<0.4,>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch<2.0.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from perceiver-multi-modality-pytorch==1.1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.6.0->perceiver-multi-modality-pytorch==1.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.6.0->perceiver-multi-modality-pytorch==1.1.0) (1.19.5)\n",
            "Installing collected packages: einops, perceiver-multi-modality-pytorch\n",
            "Successfully installed einops-0.3.0 perceiver-multi-modality-pytorch-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVcBffT3qofo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4gY_kA7oE_A",
        "outputId": "90f03c46-201b-4164-bad6-26bdd6c984a3"
      },
      "source": [
        "! git clone https://github.com/microsoft/DeepSpeed.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepSpeed'...\n",
            "remote: Enumerating objects: 8510, done.\u001b[K\n",
            "remote: Counting objects: 100% (965/965), done.\u001b[K\n",
            "remote: Compressing objects: 100% (462/462), done.\u001b[K\n",
            "remote: Total 8510 (delta 645), reused 764 (delta 491), pack-reused 7545\u001b[K\n",
            "Receiving objects: 100% (8510/8510), 17.08 MiB | 21.33 MiB/s, done.\n",
            "Resolving deltas: 100% (5730/5730), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoyuxDoroIuW",
        "outputId": "85b7a986-d5ea-40ff-a1c9-649b2f711692"
      },
      "source": [
        "! cd DeepSpeed; pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/DeepSpeed\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (0.9.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (4.41.1)\n",
            "Requirement already satisfied: tensorboardX==1.8 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (1.8)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (1.10.0.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.15+03d24fe) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed==0.3.15+03d24fe) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4.0->deepspeed==0.3.15+03d24fe) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.15+03d24fe) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.15+03d24fe) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->deepspeed==0.3.15+03d24fe) (56.0.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.3.15+03d24fe-cp37-none-any.whl size=409651 sha256=d4ac9df61c062f446750441da554bb0ee7d103c4fc607574fd8591dd1e280423\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ka8tovsl/wheels/ce/45/03/3ff604290a121d63cfe2874fc4f4f36ba7053e7d83932decd8\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: deepspeed\n",
            "  Found existing installation: deepspeed 0.3.15+03d24fe\n",
            "    Uninstalling deepspeed-0.3.15+03d24fe:\n",
            "      Successfully uninstalled deepspeed-0.3.15+03d24fe\n",
            "Successfully installed deepspeed-0.3.15+03d24fe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLo_daMOoYUM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf0dW-IoFzr3",
        "outputId": "a714e5c6-7db7-4e20-e8de-8cb35241c45c"
      },
      "source": [
        "!pip install mpi4py\n",
        "!!pip install torch==1.7.1+cu110  -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (3.0.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Looking in links: https://download.pytorch.org/whl/torch_stable.html',\n",
              " 'Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)',\n",
              " 'Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4zL1FKtB8DC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be2bb87-bbfc-4500-ee1e-9f6542eb4311"
      },
      "source": [
        "!ds_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires one of the following commands '['llvm-config', 'llvm-config-9']', but it does not exist!\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires CUDA version 10.1+, does not currently support >=11 or <10.1\n",
            "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the libraries: ['libaio-dev'] but are missing.\n",
            "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/usr/local/lib/python3.7/dist-packages/torch']\n",
            "torch version .................... 1.7.1+cu110\n",
            "torch cuda version ............... 11.0\n",
            "nvcc version ..................... 11.0\n",
            "deepspeed install path ........... ['/usr/local/lib/python3.7/dist-packages/deepspeed']\n",
            "deepspeed info ................... 0.3.15+03d24fe, 03d24fe, master\n",
            "deepspeed wheel compiled w. ...... torch 1.7, cuda 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sfl1gMZDCCpO",
        "outputId": "220ba08b-1650-46d3-9460-fbce32412287"
      },
      "source": [
        "num_epochs=10000\n",
        "\n",
        "from perceiver_pytorch.multi_modality_perceiver import  InputModality\n",
        "from perceiver_pytorch.multi_modality_with_text_perceiver import MultiModalityWithTextPerceiver, InputModalityWithEmbedding\n",
        "import torch\n",
        "\n",
        "import deepspeed\n",
        "\n",
        "video_modality = InputModalityWithEmbedding(\n",
        "    name='video',\n",
        "    input_channels=3,  # number of channels for each token of the input\n",
        "    input_axis=3,  # number of axes, 3 for video)\n",
        "    num_freq_bands=6,  # number of freq bands, with original value (2 * K + 1)\n",
        "    max_freq=4.,  # maximum frequency, hyperparameter depending on how fine the data is\n",
        ")\n",
        "image_modality = InputModalityWithEmbedding(\n",
        "    name='image',\n",
        "    input_channels=3,  # number of channels for each token of the input\n",
        "    input_axis=2,  # number of axes, 2 for images\n",
        "    num_freq_bands=6,  # number of freq bands, with original value (2 * K + 1)\n",
        "    max_freq=4.,  # maximum frequency, hyperparameter depending on how fine the data is\n",
        ")\n",
        "audio_modality = InputModalityWithEmbedding(\n",
        "    name='audio',\n",
        "    input_channels=1,  # number of channels for mono audio\n",
        "    input_axis=1,  # number of axes, 2 for images\n",
        "    num_freq_bands=6,  # number of freq bands, with original value (2 * K + 1)\n",
        "    max_freq=8.,  # maximum frequency, hyperparameter depending on how fine the data is\n",
        ")\n",
        "with deepspeed.zero.Init(\n",
        "):\n",
        " model = MultiModalityWithTextPerceiver(\n",
        "    modalities=(video_modality, image_modality),\n",
        "    depth=2,  # depth of net, combined with num_latent_blocks_per_layer to produce full Perceiver\n",
        "    num_latents=12,\n",
        "    # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "    latent_dim=64,  # latent dimension\n",
        "    cross_heads=1,  # number of heads for cross attention. paper said 1\n",
        "    latent_heads=2,  # number of heads for latent self attention, 8\n",
        "    cross_dim_head=64,\n",
        "    latent_dim_head=64,\n",
        "    num_classes=10,  # output number of classes\n",
        "    attn_dropout=0.,\n",
        "    ff_dropout=0.,\n",
        "    weight_tie_layers=True,\n",
        "    num_latent_blocks_per_layer=2 # Note that this parameter is 1 in the original Lucidrain implementation\n",
        "    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        " )\n",
        "\n",
        "\n",
        "ds_config={    \"train_batch_size\": 3,\n",
        "    \"steps_per_print\": 2000,\n",
        "    \"optimizer\": {\n",
        "      \"type\": \"Adam\",\n",
        "      \"params\": {\n",
        "        \"lr\": 0.001,\n",
        "        \"betas\": [\n",
        "          0.8,\n",
        "          0.999\n",
        "        ],\n",
        "        \"eps\": 1e-8,\n",
        "        \"weight_decay\": 3e-7\n",
        "      }\n",
        "    },\n",
        "    \"fp16\": {\n",
        "      \"enabled\": True,\n",
        "      \"loss_scale\": 1,\n",
        "      \"initial_scale_power\": 32,\n",
        "      \"loss_scale_window\": 1000,\n",
        "      \"hysteresis\": 2,\n",
        "      \"min_loss_scale\": 1\n",
        "    },\n",
        "    \"scheduler\": {\n",
        "      \"type\": \"WarmupLR\",\n",
        "      \"params\": {\n",
        "        \"warmup_min_lr\": 0,\n",
        "        \"warmup_max_lr\": 0.001,\n",
        "        \"warmup_num_steps\": 1000\n",
        "      }\n",
        "    },\n",
        "    \"wall_clock_breakdown\": False\n",
        "\n",
        "  }\n",
        "stage_3=True\n",
        "if stage_3:\n",
        "  ds_config.update({\n",
        "      \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"cpu_offload\": False,\n",
        "    \"cpu_offload_params\": False,\n",
        "    \"overlap_comm\": False,\n",
        "    \"contiguous_gradients\": False,\n",
        "    \"stage3_max_live_parameters\": 600000,\n",
        "    \"stage3_max_reuse_distance\": 10000000,\n",
        "    \"stage3_prefetch_bucket_size\": 20000,\n",
        "    \"stage3_param_persistence_threshold\": 10000,\n",
        "    \"reduce_bucket_size\": 300000,\n",
        "    \"sub_group_size\": 1e6\n",
        "  }})\n",
        "model=model.to(torch.device('cuda'))\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# Initialize DeepSpeed to use the following features\n",
        "# 1) Distributed model\n",
        "# 2) Distributed data loader\n",
        "# 3) DeepSpeed optimizer\n",
        "model_engine, optimizer, trainloader, __ = deepspeed.initialize( model=model,\n",
        "                                                                model_parameters=parameters,\n",
        "                                                                config_params=ds_config\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0\n",
        "\n",
        "      image_inputs= torch.rand(size=(3, 64, 64, 3), requires_grad=True).to(model_engine.local_rank)\n",
        "      video_inputs= torch.rand(size=(3, 2, 64, 64, 3), requires_grad=True).to(model_engine.local_rank)\n",
        "      with torch.cuda.amp.autocast():\n",
        "        outputs = model_engine({\n",
        "            'image': image_inputs,\n",
        "            'video': video_inputs\n",
        "            }\n",
        "        )\n",
        "      \n",
        "      loss = outputs.mean()\n",
        "\n",
        "      model_engine.backward(loss)\n",
        "      model_engine.step()\n",
        "print(\"DONE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-24 16:16:23,518] [INFO] [distributed.py:37:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...\n",
            "[2021-04-24 16:16:23,965] [INFO] [distributed.py:89:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.28.0.2, master_port=29500\n",
            "[2021-04-24 16:16:23,966] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "nn.functional.linear has been overridden with a more memory efficient version. This will persist unless manually reset.\n",
            "[2021-04-24 16:16:27,160] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed info: version=0.3.15+03d24fe, git-hash=03d24fe, git-branch=master\n",
            "[2021-04-24 16:16:27,162] [WARNING] [config.py:78:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.\n",
            "[2021-04-24 16:16:27,163] [WARNING] [config.py:78:_sanity_check] DeepSpeedConfig: cpu_offload_params is deprecated. Please use offload_param.\n",
            "[2021-04-24 16:16:27,174] [INFO] [engine.py:80:_initialize_parameter_parallel_groups] data_parallel_size: 1, parameter_parallel_size: 1\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/fused_adam...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 21.77649974822998 seconds\n",
            "[2021-04-24 16:16:49,666] [INFO] [engine.py:616:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2021-04-24 16:16:49,667] [INFO] [engine.py:620:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
            "Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2021-04-24 16:16:49,673] [INFO] [logging.py:60:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
            "Initializing ZeRO Stage 3\n",
            "[2021-04-24 16:16:49,746] [INFO] [utils.py:583:see_memory_usage] Stage 3 initialize beginning\n",
            "[2021-04-24 16:16:49,749] [INFO] [utils.py:588:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB \n",
            "[2021-04-24 16:16:49,753] [INFO] [utils.py:593:see_memory_usage] CPU Virtual Memory:  used = 2.66 GB, percent = 20.9%\n",
            "[2021-04-24 16:16:49,756] [INFO] [stage3.py:624:__init__] Reduce bucket size 300000\n",
            "[2021-04-24 16:16:49,758] [INFO] [stage3.py:625:__init__] Allgather bucket size 20000\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/utils...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:354: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 12.045355319976807 seconds\n",
            "[2021-04-24 16:17:01,878] [INFO] [utils.py:583:see_memory_usage] Before creating fp16 partitions\n",
            "[2021-04-24 16:17:01,880] [INFO] [utils.py:588:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB \n",
            "[2021-04-24 16:17:01,883] [INFO] [utils.py:593:see_memory_usage] CPU Virtual Memory:  used = 2.66 GB, percent = 20.9%\n",
            "[2021-04-24 16:17:01,885] [INFO] [stage3.py:39:print_rank_0] fp16 group 0 has 1 subgroups\n",
            "[2021-04-24 16:17:01,901] [INFO] [stage3.py:39:print_rank_0] Swappable FP32 Partitions: count=0 size= 0.00 GB\n",
            "[2021-04-24 16:17:01,902] [INFO] [stage3.py:39:print_rank_0] In-Memory FP32 Partitions: count=1 size= 0.00 GB\n",
            "[2021-04-24 16:17:01,905] [INFO] [stage3.py:819:__init__] optimizer state initialized\n",
            "[2021-04-24 16:17:01,906] [INFO] [stage3.py:39:print_rank_0] Largest partitioned param numel = 377914\n",
            "[2021-04-24 16:17:01,992] [INFO] [utils.py:583:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2021-04-24 16:17:01,994] [INFO] [utils.py:588:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2021-04-24 16:17:01,996] [INFO] [utils.py:593:see_memory_usage] CPU Virtual Memory:  used = 2.66 GB, percent = 20.9%\n",
            "[2021-04-24 16:17:01,999] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2021-04-24 16:17:02,000] [INFO] [engine.py:451:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2021-04-24 16:17:02,002] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fbba0557410>\n",
            "[2021-04-24 16:17:02,004] [INFO] [logging.py:60:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-04-24 16:17:02,005] [INFO] [config.py:743:print] DeepSpeedEngine configuration:\n",
            "[2021-04-24 16:17:02,007] [INFO] [config.py:747:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2021-04-24 16:17:02,009] [INFO] [config.py:747:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2021-04-24 16:17:02,011] [INFO] [config.py:747:print]   allreduce_always_fp32 ........ False\n",
            "[2021-04-24 16:17:02,012] [INFO] [config.py:747:print]   amp_enabled .................. False\n",
            "[2021-04-24 16:17:02,013] [INFO] [config.py:747:print]   amp_params ................... False\n",
            "[2021-04-24 16:17:02,015] [INFO] [config.py:747:print]   checkpoint_tag_validation_enabled  True\n",
            "[2021-04-24 16:17:02,016] [INFO] [config.py:747:print]   checkpoint_tag_validation_fail  False\n",
            "[2021-04-24 16:17:02,018] [INFO] [config.py:747:print]   disable_allgather ............ False\n",
            "[2021-04-24 16:17:02,019] [INFO] [config.py:747:print]   dump_state ................... False\n",
            "[2021-04-24 16:17:02,021] [INFO] [config.py:747:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2021-04-24 16:17:02,023] [INFO] [config.py:747:print]   elasticity_enabled ........... False\n",
            "[2021-04-24 16:17:02,024] [INFO] [config.py:747:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 3, \n",
            "    \"detailed\": true\n",
            "}\n",
            "[2021-04-24 16:17:02,025] [INFO] [config.py:747:print]   fp16_enabled ................. True\n",
            "[2021-04-24 16:17:02,027] [INFO] [config.py:747:print]   global_rank .................. 0\n",
            "[2021-04-24 16:17:02,028] [INFO] [config.py:747:print]   gradient_accumulation_steps .. 1\n",
            "[2021-04-24 16:17:02,030] [INFO] [config.py:747:print]   gradient_clipping ............ 0.0\n",
            "[2021-04-24 16:17:02,031] [INFO] [config.py:747:print]   gradient_predivide_factor .... 1.0\n",
            "[2021-04-24 16:17:02,033] [INFO] [config.py:747:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2021-04-24 16:17:02,035] [INFO] [config.py:747:print]   loss_scale ................... 1\n",
            "[2021-04-24 16:17:02,037] [INFO] [config.py:747:print]   memory_breakdown ............. False\n",
            "[2021-04-24 16:17:02,038] [INFO] [config.py:747:print]   optimizer_legacy_fusion ...... False\n",
            "[2021-04-24 16:17:02,039] [INFO] [config.py:747:print]   optimizer_name ............... adam\n",
            "[2021-04-24 16:17:02,041] [INFO] [config.py:747:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2021-04-24 16:17:02,044] [INFO] [config.py:747:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2021-04-24 16:17:02,046] [INFO] [config.py:747:print]   pld_enabled .................. False\n",
            "[2021-04-24 16:17:02,050] [INFO] [config.py:747:print]   pld_params ................... False\n",
            "[2021-04-24 16:17:02,051] [INFO] [config.py:747:print]   prescale_gradients ........... False\n",
            "[2021-04-24 16:17:02,053] [INFO] [config.py:747:print]   scheduler_name ............... WarmupLR\n",
            "[2021-04-24 16:17:02,055] [INFO] [config.py:747:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
            "[2021-04-24 16:17:02,057] [INFO] [config.py:747:print]   sparse_attention ............. None\n",
            "[2021-04-24 16:17:02,059] [INFO] [config.py:747:print]   sparse_gradients_enabled ..... False\n",
            "[2021-04-24 16:17:02,062] [INFO] [config.py:747:print]   steps_per_print .............. 2000\n",
            "[2021-04-24 16:17:02,063] [INFO] [config.py:747:print]   tensorboard_enabled .......... False\n",
            "[2021-04-24 16:17:02,065] [INFO] [config.py:747:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
            "[2021-04-24 16:17:02,066] [INFO] [config.py:747:print]   tensorboard_output_path ...... \n",
            "[2021-04-24 16:17:02,070] [INFO] [config.py:747:print]   train_batch_size ............. 3\n",
            "[2021-04-24 16:17:02,072] [INFO] [config.py:747:print]   train_micro_batch_size_per_gpu  3\n",
            "[2021-04-24 16:17:02,077] [INFO] [config.py:747:print]   wall_clock_breakdown ......... False\n",
            "[2021-04-24 16:17:02,086] [INFO] [config.py:747:print]   world_size ................... 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:354: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021-04-24 16:17:02,097] [INFO] [config.py:747:print]   zero_allow_untested_optimizer  False\n",
            "[2021-04-24 16:17:02,099] [INFO] [config.py:747:print]   zero_config .................. {\n",
            "    \"stage\": 3, \n",
            "    \"contiguous_gradients\": false, \n",
            "    \"reduce_scatter\": false, \n",
            "    \"reduce_bucket_size\": 3.000000e+05, \n",
            "    \"allgather_partitions\": true, \n",
            "    \"allgather_bucket_size\": 5.000000e+08, \n",
            "    \"overlap_comm\": false, \n",
            "    \"load_from_fp32_weights\": true, \n",
            "    \"elastic_checkpoint\": true, \n",
            "    \"offload_param\": null, \n",
            "    \"offload_optimizer\": null, \n",
            "    \"sub_group_size\": 1.000000e+06, \n",
            "    \"prefetch_bucket_size\": 2.000000e+04, \n",
            "    \"param_persistence_threshold\": 1.000000e+04, \n",
            "    \"max_live_parameters\": 6.000000e+05, \n",
            "    \"max_reuse_distance\": 1.000000e+07, \n",
            "    \"gather_fp16_weights_on_model_save\": false\n",
            "}\n",
            "[2021-04-24 16:17:02,100] [INFO] [config.py:747:print]   zero_enabled ................. True\n",
            "[2021-04-24 16:17:02,101] [INFO] [config.py:747:print]   zero_optimization_stage ...... 3\n",
            "[2021-04-24 16:17:02,103] [INFO] [config.py:754:print]   json = {\n",
            "    \"train_batch_size\": 3, \n",
            "    \"steps_per_print\": 2.000000e+03, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.8, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 3e-07\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 1, \n",
            "        \"initial_scale_power\": 32, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 0.001, \n",
            "            \"warmup_num_steps\": 1000\n",
            "        }\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 3, \n",
            "        \"cpu_offload\": false, \n",
            "        \"cpu_offload_params\": false, \n",
            "        \"overlap_comm\": false, \n",
            "        \"contiguous_gradients\": false, \n",
            "        \"stage3_max_live_parameters\": 6.000000e+05, \n",
            "        \"stage3_max_reuse_distance\": 1.000000e+07, \n",
            "        \"stage3_prefetch_bucket_size\": 2.000000e+04, \n",
            "        \"stage3_param_persistence_threshold\": 1.000000e+04, \n",
            "        \"reduce_bucket_size\": 3.000000e+05, \n",
            "        \"sub_group_size\": 1.000000e+06\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0007159709930419922 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-250063ddea6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0mmodel_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m       \u001b[0mmodel_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, allreduce_gradients, release_loss)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             self.optimizer.is_gradient_accumulation_boundary = self.is_gradient_accumulation_boundary(\n\u001b[1;32m   1024\u001b[0m             )\n\u001b[0;32m-> 1025\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# AMP requires delaying unscale when inside gradient accumulation boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/zero/stage3.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipg_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m         '''Partitioning Parameters that were not partitioned\n\u001b[1;32m   2946\u001b[0m         \u001b[0mUsually\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0minput\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/fp16/loss_scaler.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mscaled_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_bwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwd_used_autocast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_bwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/zero/linear.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#print(f\"Computing grad input weight {weight.shape} grad_output {grad_output.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;31m#print(f\"Computed grad input {grad_input.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EZhS-DZT18B"
      },
      "source": [
        "ONE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}